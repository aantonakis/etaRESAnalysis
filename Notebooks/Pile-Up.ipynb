{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140752e-59ba-4f99-a57d-e485de59c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Explore the Neutrino pile up normalized by events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1db124-d84b-43e9-a04f-7f5954b85e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h5py\n",
    "import gzip\n",
    "import math\n",
    "import timeit\n",
    "\n",
    "# First attempt\n",
    "#infile = \"../NTuples/eta_production_ntuple_test_nodirt.root\"\n",
    "\n",
    "# Latest Eta Production\n",
    "#infile = \"../NTuples/eta_production_nodirt_ntuple_batch1.root\"\n",
    "\n",
    "# MC CV Sample --> Low Stats\n",
    "#infile = \"../NTuples/mc_production_with_fmatch_ntuple.root\"\n",
    "\n",
    "#MC CV Sample --> High Stats\n",
    "#infile = \"../NTuples/mc_production_with_fmatch_ntuple_more_stats.root\"\n",
    "infile = \"../NTuples/mc_production_with_fmatch_ntuple_more_stats_v2.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e700b1-603b-46b8-80f1-6f49a2e508df",
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile = uproot.open(infile)\n",
    "\n",
    "inFileROOT = ROOT.TFile.Open(infile, \"READ\")\n",
    "#h_tot_pot = inFileROOT.Get(\"TotalPOT\")\n",
    "h_tot_pot = inFileROOT.Get(\"TOTPOT_Clone\")\n",
    "TOT_POT = h_tot_pot.GetBinContent(1)\n",
    "inFileROOT.Close()\n",
    "TOT_POT = f\"{TOT_POT:.2e}\"\n",
    "print(\"Total POT\", TOT_POT)\n",
    "\n",
    "#slc_tree = inFile[\"slc_truth_tree\"]\n",
    "slc_tree = inFile[\"slc_truth_tree\"]\n",
    "slc_reco_tree = inFile[\"slc_tree\"]\n",
    "pfp_tree = inFile[\"pfp_tree\"]\n",
    "\n",
    "cosmic_tree1 = inFile[\"cosmic_tree1\"]\n",
    "cosmic_tree2 = inFile[\"cosmic_tree2\"]\n",
    "\n",
    "particle_tree1 = inFile[\"particle_tree1\"]\n",
    "particle_tree2 = inFile[\"particle_tree2\"]\n",
    "\n",
    "pfp_df = pfp_tree.arrays(pfp_tree.keys(), library=\"pd\")\n",
    "\n",
    "slc_df = slc_tree.arrays(slc_tree.keys(), library=\"pd\")\n",
    "slc_reco_df = slc_reco_tree.arrays(slc_reco_tree.keys(), library=\"pd\")\n",
    "\n",
    "\n",
    "particle_df1 = particle_tree1.arrays(particle_tree1.keys(), library=\"pd\")\n",
    "particle_df2 = particle_tree2.arrays(particle_tree2.keys(), library=\"pd\")\n",
    "\n",
    "cosmic_df1 = cosmic_tree1.arrays(cosmic_tree1.keys(), library=\"pd\")\n",
    "cosmic_df2 = cosmic_tree2.arrays(cosmic_tree2.keys(), library=\"pd\")\n",
    "\n",
    "slc_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb7cc4-d391-4a4e-877e-7e700c55085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isTPC(row):\n",
    "    if (-200 <= row[\"vtx_x\"] <= 200) and (-200 <= row[\"vtx_y\"] <= 200) and (0 <= row[\"vtx_z\"] <= 500):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "slc_df[\"inTPC\"] = slc_df.apply(isTPC, axis=1)\n",
    "slc_reco_df[\"inTPC\"] = slc_reco_df.apply(isTPC, axis=1)\n",
    "slc_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0386a-4a04-45a2-8b15-6e5b8296502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pdg_counts_to_slices(slc_df_t, other_df, pdg, new_col):\n",
    "    filtered = other_df[other_df['pdg'] == pdg]\n",
    "\n",
    "    # Step 2: Group by run and subrun and count occurrences\n",
    "    counts = filtered.groupby(['run', 'subrun', 'evt', 'slc']).size()\n",
    "\n",
    "    # Step 3: Map the counts to the smaller DataFrame\n",
    "    slc_df_t[new_col] = slc_df_t.set_index(['run', 'subrun', 'evt', 'slc']).index.map(counts).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "map_pdg_counts_to_slices(slc_df, particle_df1, 111, \"npi0\")\n",
    "map_pdg_counts_to_slices(slc_df, particle_df1, 221, \"neta\")\n",
    "map_pdg_counts_to_slices(slc_df, particle_df1, 22, \"ngamma\")\n",
    "map_pdg_counts_to_slices(slc_df, particle_df1, 13, \"nmuminus\")\n",
    "\n",
    "slc_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baee4e-3a13-49db-8ff2-7fa6fe0f4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "topology_labels = {\n",
    "    0:r\"$\\nu_{\\mu} CC$\",\n",
    "    1:r\"$\\nu_{\\mu} NC$\",\n",
    "    2:r\"$\\nu_{e} CC$\",\n",
    "    3:r\"$\\nu_{e} NC$\",\n",
    "    4:r\"$\\bar{\\nu}_{\\mu}$\",\n",
    "    5:r\"$\\bar{\\nu}_{e}$\",\n",
    "    6:r\"DIRT $\\nu$\",\n",
    "    7:\"Cosmic\",\n",
    "}\n",
    "\n",
    "topology_selections = {\n",
    "    0:\"pdg == 14.0 and iscc == 1.0 and inTPC == 1\",\n",
    "    1:\"pdg == 14.0 and isnc == 1.0 and inTPC == 1\",\n",
    "    2:\"pdg == 12.0 and iscc == 1.0 and inTPC == 1\",\n",
    "    3:\"pdg == 12.0 and isnc == 1.0 and inTPC == 1\",\n",
    "    4:\"pdg == -14.0 and inTPC == 1\",\n",
    "    5:\"pdg == -12.0 and inTPC == 1\",\n",
    "    6:\"(pdg == 14.0 or pdg == 12.0 or pdg == -14.0 or pdg == -12.0 ) and inTPC == 0\",\n",
    "    7:\"pdg == -1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4534b-0f29-48e5-826d-e71ce34869c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(len(topology_selections.keys())):\n",
    "    #temp = slc_df.query(topology_selections[num])\n",
    "    condition = slc_df.index.isin(slc_df.query(topology_selections[num]).index)\n",
    "    slc_df.loc[condition, \"TOP\"] = num\n",
    "\n",
    "slc_reco_df[\"TOP\"] = slc_df[\"TOP\"]\n",
    "slc_reco_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c084e83-d32d-413d-a400-3e5d294ccd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topology labels to other dataframes\n",
    "df_small_filtered = slc_df[['run', 'subrun', 'evt', 'slc', 'TOP']]\n",
    "\n",
    "pfp_df = pfp_df.merge(df_small_filtered, on=['run', 'subrun', 'evt', 'slc'], how='left')\n",
    "#cosmic_df1 = cosmic_df1.merge(df_small_filtered, on=['run', 'subrun', 'evt', 'slc'], how='left')\n",
    "particle_df1 = particle_df1.merge(df_small_filtered, on=['run', 'subrun', 'evt', 'slc'], how='left')\n",
    "slc_reco_df[\"TOP\"] = slc_df[\"TOP\"]\n",
    "particle_df1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42848e83-5efd-4d0a-92f8-fb4ada0c53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = slc_df[\"run\"].values\n",
    "subruns = slc_df[\"subrun\"].values\n",
    "evts = slc_df[\"evt\"].values\n",
    "\n",
    "data = {'run': runs,\n",
    "        'subrun': subruns,\n",
    "        'evt': evts}\n",
    "\n",
    "event_df = pd.DataFrame(data)\n",
    "\n",
    "event_df = event_df.drop_duplicates()\n",
    "\n",
    "# Drop duplicates to find unique combinations\n",
    "#unique_combinations = event_df.drop_duplicates()\n",
    "\n",
    "# Get the number of unique combinations\n",
    "N_EVENTS = event_df.shape[0]\n",
    "\n",
    "print(\"N_EVENTS:\", N_EVENTS)\n",
    "\n",
    "\n",
    "# Get the Event Normalization\n",
    "#N_EVENTS = slc_df.groupby(['run', 'subrun']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266004f3-670a-4820-bc64-1ee8be998ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_top_to_events(evt_df_t, other_df, top, new_col):\n",
    "    filtered = other_df[other_df['TOP'] == top]\n",
    "\n",
    "    # Step 2: Group by run and subrun and count occurrences\n",
    "    counts = filtered.groupby(['run', 'subrun', 'evt']).size()\n",
    "\n",
    "    # Step 3: Map the counts to the smaller DataFrame\n",
    "    evt_df_t[new_col] = evt_df_t.set_index(['run', 'subrun', 'evt']).index.map(counts).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    map_top_to_events(event_df, slc_df, num, str(num))\n",
    "\n",
    "event_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ac29c-92f7-4db6-a05e-dfb354b3e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before any beam window selection\n",
    "\n",
    "B = np.linspace(0.5, 30.5, 32)\n",
    "\n",
    "print(B)\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    d = event_df[str(num)].values\n",
    "    w = np.ones_like(d)*(1.0/N_EVENTS)\n",
    "    plt.hist(d, bins=B, weights=w, histtype=\"step\", linewidth=2, label=topology_labels[num])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Slice Multiplicity [Counts]\", fontsize=14)\n",
    "plt.ylabel(\"Counts/Event/bin/\"+str(TOT_POT)+\" POT\", fontsize=14)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"No Beam Window Selection\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b119f-1f58-419b-9774-c4e64ba07669",
   "metadata": {},
   "outputs": [],
   "source": [
    "B= np.linspace(0, 5, 20)\n",
    "plt.hist(slc_reco_df.query(\"TOP == 7 and (0 < fmatch_time < 5)\")[\"fmatch_time\"], bins=B, \n",
    "         histtype=\"step\", linewidth=2, label=\"Cosmic\")\n",
    "\n",
    "plt.hist(slc_reco_df.query(\"TOP != 7 and (0 < fmatch_time < 5)\")[\"fmatch_time\"], bins=B, \n",
    "         histtype=\"step\", linewidth=2, label=r\"$\\nu$\")\n",
    "plt.xlabel(\"Flash Match Time\", fontsize=14)\n",
    "plt.ylabel(\"Slice Count/bin/\"+str(TOT_POT)+\" POT\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5deb01b-4c38-4906-afdc-35ae452b75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_reco_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a5749-65ab-4957-8495-fdd90e3eb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "B= np.linspace(0, 5, 20)\n",
    "plt.hist(slc_reco_df.query(\"TOP == 7 and (0 < fmatch_time < 5) and (is_clear_cosmic == 0.0)\")[\"fmatch_time\"], bins=B, \n",
    "         histtype=\"step\", linewidth=2, label=\"Cosmic\")\n",
    "\n",
    "plt.hist(slc_reco_df.query(\"TOP != 7 and (0 < fmatch_time < 5) and (is_clear_cosmic == 0.0)\")[\"fmatch_time\"], bins=B, \n",
    "         histtype=\"step\", linewidth=2, label=r\"$\\nu$\")\n",
    "plt.xlabel(\"Flash Match Time\", fontsize=14)\n",
    "plt.ylabel(\"Slice Count/bin/\"+str(TOT_POT)+\" POT\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79243e77-d879-4230-818d-21001c4775a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make the clear cosmic cut\n",
    "slc_reco_df_clear = slc_reco_df.query(\"is_clear_cosmic == 0.0\")\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    map_top_to_events(event_df, slc_reco_df_clear, num, str(num))\n",
    "\n",
    "event_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ce525-3d23-4dd5-a15d-ebeb7292e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before any beam window selection\n",
    "\n",
    "#B = np.linspace(0.5, 30.5, 32)\n",
    "B = np.arange(0.5, 30.5, 1)\n",
    "\n",
    "print(B)\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    d = event_df[str(num)].values\n",
    "    w = np.ones_like(d)*(1.0/N_EVENTS)\n",
    "    plt.hist(d, bins=B, weights=w, histtype=\"step\", linewidth=2, label=topology_labels[num])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Slice Multiplicity [Counts]\", fontsize=14)\n",
    "plt.ylabel(\"Counts/Event/bin/\"+str(TOT_POT)+\" POT\", fontsize=14)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Clear Cosmic Selection\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ca277-a200-476b-aa63-3f41b895ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on the beam window\n",
    "\n",
    "slc_reco_df_clear_beam = slc_reco_df.query(\"(is_clear_cosmic == 0.0) and (0 <= fmatch_time <= 2.1)\")\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    map_top_to_events(event_df, slc_reco_df_clear_beam, num, str(num))\n",
    "\n",
    "event_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49222a37-8efa-41dc-a1fe-646589c20333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_centers = (B[:-1] + B[1:]) / 2  # calculate bin centers\n",
    "bin_width = B[1] - B[0]\n",
    "\n",
    "count_arr = []\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    d = event_df[str(num)].values\n",
    "    w = np.ones_like(d)*(1.0/N_EVENTS)\n",
    "    c, e, _ = plt.hist(d, bins=B, weights=w, histtype=\"step\", linewidth=2, label=topology_labels[num])\n",
    "    if num != 6 and num != 7:\n",
    "        count_arr.append(c*N_EVENTS)\n",
    "\n",
    "all_nus = np.zeros_like(count_arr[0])\n",
    "\n",
    "for c in count_arr:\n",
    "    all_nus += c\n",
    "\n",
    "\n",
    "\n",
    "plt.errorbar(bin_centers, all_nus/N_EVENTS, \n",
    "            xerr=np.ones_like(all_nus)*0.5, yerr=np.sqrt(all_nus)/N_EVENTS, fmt=\"o\", c=\"black\", label=r\"$\\nu$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Slice Multiplicity [Counts]\", fontsize=14)\n",
    "plt.ylabel(\"Counts/Event/bin/\"+str(TOT_POT)+\" POT\", fontsize=14)\n",
    "plt.xlim([0, 10])\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Clear Cosmic Selection + Beam Window\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af6479-5493-48b0-a4aa-e5b76e986e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_reco_df_beam = slc_reco_df.query(\"0 <= fmatch_time <= 2.1\")\n",
    "\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    map_top_to_events(event_df, slc_reco_df_beam, num, str(num))\n",
    "\n",
    "event_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eda918-4cb3-4a5b-b5cb-e36fb9218f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_arr = []\n",
    "\n",
    "all_counts = []\n",
    "for num in range(len(topology_labels.keys())):\n",
    "    d = event_df[str(num)].values\n",
    "    w = np.ones_like(d)*(1.0/N_EVENTS)\n",
    "    c, e, _ = plt.hist(d, bins=B, weights=w, histtype=\"step\", linewidth=2, label=topology_labels[num])\n",
    "    all_counts.append(c*N_EVENTS)\n",
    "    if num != 6 and num != 7:\n",
    "        count_arr.append(c*N_EVENTS)\n",
    "\n",
    "all_nus = np.zeros_like(count_arr[0])\n",
    "\n",
    "for c in count_arr:\n",
    "    all_nus += c\n",
    "\n",
    "plt.errorbar(bin_centers, all_nus/N_EVENTS, \n",
    "            xerr=np.ones_like(all_nus)*0.5, yerr=np.sqrt(all_nus)/N_EVENTS, fmt=\"o\", c=\"black\", label=r\"$\\nu$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Slice Multiplicity [Counts]\", fontsize=14)\n",
    "plt.ylabel(\"Counts/Event/bin/\"+str(TOT_POT)+\" POT\", fontsize=14)\n",
    "plt.xlim([0, 10])\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Beam Window Selection Only\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160f861-0e4d-4366-8103-6b081aa245d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((1.0*sum(all_counts[-1]))/N_EVENTS)\n",
    "print((1.0*sum(all_counts[-2]))/N_EVENTS)\n",
    "\n",
    "nu_sum = 0\n",
    "for c in count_arr:\n",
    "    nu_sum += sum(c)\n",
    "    \n",
    "print((1.0*nu_sum)/N_EVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b4c51-e93b-4787-a3f8-23794e350c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_nu_multiplicity(row):\n",
    "    r, sr, e = row[\"run\"], row[\"subrun\"], row[\"evt\"]\n",
    "    m1 = (slc_df[\"run\"].values == r)\n",
    "    m2 = (slc_df[\"subrun\"].values == sr)\n",
    "    m3 = (slc_df[\"evt\"].values == e)\n",
    "    m = m1 & m2 & m3\n",
    "    tops = np.array(slc_df[\"TOP\"].values)[m]\n",
    "    m1 = (tops != 7) # not cosmic\n",
    "    m2 = (tops != 6) # not dirt\n",
    "    m = m1 & m2\n",
    "    n = sum(m)\n",
    "    return n\n",
    "\n",
    "print(\"made an event selection function\")\n",
    "\n",
    "event_df[\"N_AV_NU\"] = event_df.apply(get_event_nu_multiplicity, axis=1)\n",
    "event_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37948d-6539-4af5-b5bf-4507a7d1b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_nu = 1.0*event_df.query(\"N_AV_NU > 0\").shape[0]\n",
    "\n",
    "print(N_nu/event_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091d873-4492-42a0-9915-0025842bb403",
   "metadata": {},
   "source": [
    "# Let's Try an Event Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33f25a-eb84-4451-bb07-6be7fffccd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each unique event\n",
    "N_nu = 0\n",
    "for num in range(event_df.shape[0]):\n",
    "    tops = get_event_tops(event_df.iloc[num])\n",
    "    m1 = (tops != 7) # not cosmic\n",
    "    m2 = (tops != 6) # not dirt\n",
    "    m = m1 & m2\n",
    "    n = sum(m)\n",
    "    if n > 0:\n",
    "        N_nu += 1\n",
    "\n",
    "print((1.0*N_nu)/event_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335644d-c915-4436-a867-91f1342ab6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyROOT_3.9_env",
   "language": "python",
   "name": "pyroot_3.9_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
